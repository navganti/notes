@book{absilOptimizationAlgorithmsMatrix2008,
  title = {Optimization Algorithms on Matrix Manifolds},
  author = {Absil, P.-A. and Mahony, R. and Sepulchre, R.},
  date = {2008},
  publisher = {{Princeton University Press}},
  location = {{Princeton, N.J. ; Woodstock}},
  isbn = {978-0-691-13298-3},
  pagetotal = {224},
  keywords = {Algorithms,Mathematical optimization,Matrices},
  annotation = {OCLC: ocn174129993}
}

@book{ahrensHowTakeSmart2017,
  title = {How to Take Smart Notes: One Simple Technique to Boost Writing, Learning and Thinking: For Students, Academics and Nonfiction Book Writers},
  shorttitle = {How to Take Smart Notes},
  author = {Ahrens, Sönke},
  date = {2017},
  publisher = {{CreateSpace}},
  location = {{North Charleston, SC}},
  isbn = {978-1-5428-6650-7},
  langid = {english},
  pagetotal = {170}
}

@book{barfootStateEstimationRobotics2020,
  title = {State {{Estimation}} for {{Robotics}}},
  author = {Barfoot, Timothy D.},
  date = {2020},
  publisher = {{Cambridge University Press.}},
  isbn = {978-1-316-67152-8 978-1-107-15939-6},
  langid = {english},
  annotation = {OCLC: 1117851942}
}

@unpublished{bloeschPrimerDifferentialCalculus2016,
  title = {A {{Primer}} on the {{Differential Calculus}} of {{3D Orientations}}},
  author = {Bloesch, Michael and Sommer, Hannes and Laidlow, Tristan and Burri, Michael and Nuetzi, Gabriel and Fankhauser, Péter and Bellicoso, Dario and Gehring, Christian and Leutenegger, Stefan and Hutter, Marco and Siegwart, Roland},
  date = {2016-10-31},
  eprint = {1606.05285},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1606.05285},
  urldate = {2022-02-04},
  abstract = {The proper handling of 3D orientations is a central element in many optimization problems in engineering. Unfortunately many researchers and engineers struggle with the formulation of such problems and often fall back to suboptimal solutions. The existence of many different conventions further complicates this issue, especially when interfacing multiple differing implementations. This document discusses an alternative approach which makes use of a more abstract notion of 3D orientations. The relative orientation between two coordinate systems is primarily identified by the coordinate mapping it induces. This is combined with the standard exponential map in order to introduce representation-independent and minimal differentials, which are very convenient in optimization based methods.},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {C:\Users\Nav\Zotero\storage\NJ62LEHU\Bloesch et al. - 2016 - A Primer on the Differential Calculus of 3D Orient.pdf}
}

@article{bogdollAnomalyDetectionAutonomous2021,
  title = {Anomaly {{Detection}} in {{Autonomous Driving}}: {{A Survey}}},
  author = {Bogdoll, Daniel and Nitsche, Maximilian and Zollner, J Marius},
  date = {2021},
  pages = {12},
  abstract = {Nowadays, there are outstanding strides towards a future with autonomous vehicles on our roads. While the perception of autonomous vehicles performs well under closed-set conditions, they still struggle to handle the unexpected. This survey provides an extensive overview of anomaly detection techniques based on camera, lidar, radar, multimodal and abstract object level data. We provide a systematization including detection approach, corner case level, ability for an online application, and further attributes. We outline the state-of-the-art and point out current research gaps.},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\M82PG8JU\Bogdoll et al. - 2021 - Anomaly Detection in Autonomous Driving A Survey.pdf}
}

@book{boydConvexOptimization2004,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  date = {2004},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge, UK ; New York}},
  isbn = {978-0-521-83378-3},
  pagetotal = {716},
  keywords = {Convex functions,Mathematical optimization}
}

@book{bryantComputerSystemsProgrammer2016,
  title = {Computer Systems: A Programmer's Perspective},
  shorttitle = {Computer Systems},
  author = {Bryant, Randal E. and O'Hallaron, David},
  date = {2016},
  edition = {Third edition, global edition},
  publisher = {{Pearson Education}},
  location = {{Boston München}},
  isbn = {978-1-292-10176-7},
  langid = {english},
  pagetotal = {1120}
}

@inproceedings{choiEncoderlessGimbalCalibration2018,
  title = {Encoderless {{Gimbal Calibration}} of {{Dynamic Multi-Camera Clusters}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Choi, Christopher L. and Rebello, Jason and Koppel, Leonid and Ganti, Pranav and Das, Arun and Waslander, Steven L.},
  date = {2018-05},
  pages = {2126--2133},
  publisher = {{IEEE}},
  location = {{Brisbane, QLD}},
  doi = {10.1109/ICRA.2018.8462920},
  url = {https://ieeexplore.ieee.org/document/8462920/},
  urldate = {2022-01-30},
  eventtitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-5386-3081-5},
  file = {C:\Users\Nav\Zotero\storage\QJ6W525F\Choi et al. - 2018 - Encoderless Gimbal Calibration of Dynamic Multi-Ca.pdf}
}

@book{deisenrothMathematicsMachineLearning2020,
  title = {Mathematics for Machine Learning},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  date = {2020},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge, UK New York, NY}},
  abstract = {"The fundamental mathematical tools needed to understand machine learning include linear algebra, analytic geometry, matrix decompositions, vector calculus, optimization, probability, and statistics. These topics are traditionally taught in disparate courses, making it hard for data science or computer science students, or professionals, to efficiently learn the mathematics. This self-contained textbook bridges the gap between mathematical and machine learning texts, introducing the mathematical concepts with a minimum of prerequisites. It uses these concepts to derive four central machine learning methods: linear regression, principal component analysis, Gaussian mixture models, and support vector machines. For students and others with a mathematical background, these derivations provide a starting point to machine learning texts. For those learning the mathematics for the first time, the methods help build intuition and practical experience with applying mathematical concepts"},
  isbn = {978-1-108-47004-9 978-1-108-45514-5},
  langid = {english}
}

@article{eadeGaussNewtonLevenbergMarquardtOptimization,
  title = {Gauss-{{Newton}} / {{Levenberg-Marquardt Optimization}}},
  author = {Eade, Ethan},
  pages = {9},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\5WRJTXQ3\Eade - Gauss-Newton  Levenberg-Marquardt Optimization.pdf}
}

@article{eadeLieGroups2D,
  title = {Lie {{Groups}} for {{2D}} and {{3D Transformations}}},
  author = {Eade, Ethan},
  pages = {25},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\ZUT6A6HX\Eade - Lie Groups for 2D and 3D Transformations.pdf}
}

@article{eadeLieGroupsComputer,
  title = {Lie {{Groups}} for {{Computer Vision}}},
  author = {Eade, Ethan},
  pages = {15},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\XDTQAT3B\Eade - Lie Groups for Computer Vision.pdf}
}

@inproceedings{forsterIMUPreintegrationManifold2015,
  title = {{{IMU Preintegration}} on {{Manifold}} for {{Efficient Visual-Inertial Maximum-a-Posteriori Estimation}}},
  booktitle = {Robotics: {{Science}} and {{Systems XI}}},
  author = {Forster, Christian and Carlone, Luca and Dellaert, Frank and Scaramuzza, Davide},
  date = {2015-07-13},
  publisher = {{Robotics: Science and Systems Foundation}},
  doi = {10.15607/RSS.2015.XI.006},
  url = {http://www.roboticsproceedings.org/rss11/p06.pdf},
  urldate = {2022-02-07},
  abstract = {Recent results in monocular visual-inertial navigation (VIN) have shown that optimization-based approaches outperform filtering methods in terms of accuracy due to their capability to relinearize past states. However, the improvement comes at the cost of increased computational complexity. In this paper, we address this issue by preintegrating inertial measurements between selected keyframes. The preintegration allows us to accurately summarize hundreds of inertial measurements into a single relative motion constraint. Our first contribution is a preintegration theory that properly addresses the manifold structure of the rotation group and carefully deals with uncertainty propagation. The measurements are integrated in a local frame, which eliminates the need to repeat the integration when the linearization point changes while leaving the opportunity for belated bias corrections. The second contribution is to show that the preintegrated IMU model can be seamlessly integrated in a visual-inertial pipeline under the unifying framework of factor graphs. This enables the use of a structureless model for visual measurements, further accelerating the computation. The third contribution is an extensive evaluation of our monocular VIN pipeline: experimental results confirm that our system is very fast and demonstrates superior accuracy with respect to competitive state-of-the-art filtering and optimization algorithms, including off-the-shelf systems such as Google Tango [1].},
  eventtitle = {Robotics: {{Science}} and {{Systems}} 2015},
  isbn = {978-0-9923747-1-6},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\M42NFHDC\Forster et al. - 2015 - IMU Preintegration on Manifold for Efficient Visua.pdf}
}

@article{forsterOnManifoldPreintegrationRealTime2017,
  title = {On-{{Manifold Preintegration}} for {{Real-Time Visual--Inertial Odometry}}},
  author = {Forster, Christian and Carlone, Luca and Dellaert, Frank and Scaramuzza, Davide},
  date = {2017-02},
  journaltitle = {IEEE Transactions on Robotics},
  shortjournal = {IEEE Trans. Robot.},
  volume = {33},
  number = {1},
  pages = {1--21},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2016.2597321},
  url = {https://ieeexplore.ieee.org/document/7557075/},
  urldate = {2022-02-07},
  file = {C:\Users\Nav\Zotero\storage\ML8VTY7C\Forster et al. - 2017 - On-Manifold Preintegration for Real-Time Visual--I.pdf}
}

@online{furgaleRepresentingRobotPose,
  title = {Representing {{Robot Pose}}: {{The}} Good, the Bad, and the Ugly.},
  shorttitle = {Representing {{Robot Pose}}},
  author = {Furgale, Paul},
  url = {http://paulfurgale.info/news/2014/6/9/representing-robot-pose-the-good-the-bad-and-the-ugly},
  urldate = {2022-02-03},
  langid = {american},
  organization = {{Paul Furgale}},
  file = {C:\Users\Nav\Zotero\storage\Q36JJMBJ\representing-robot-pose-the-good-the-bad-and-the-ugly.html}
}

@inproceedings{gantiNetworkUncertaintyInformed2019,
  title = {Network {{Uncertainty Informed Semantic Feature Selection}} for {{Visual SLAM}}},
  booktitle = {2019 16th {{Conference}} on {{Computer}} and {{Robot Vision}} ({{CRV}})},
  author = {Ganti, Pranav and Waslander, Steven L.},
  date = {2019-05},
  pages = {121--128},
  publisher = {{IEEE}},
  location = {{Kingston, QC, Canada}},
  doi = {10.1109/CRV.2019.00024},
  url = {https://ieeexplore.ieee.org/document/8781616/},
  urldate = {2022-01-30},
  eventtitle = {2019 16th {{Conference}} on {{Computer}} and {{Robot Vision}} ({{CRV}})},
  isbn = {978-1-72811-838-3},
  file = {C:\Users\Nav\Zotero\storage\HDE8GTAQ\Ganti and Waslander - 2019 - Network Uncertainty Informed Semantic Feature Sele.pdf}
}

@thesis{gantiSemanticallyInformedVisual,
  title = {Semantically {{Informed Visual Odometry}} and {{Mapping}}},
  author = {Ganti, Pranav},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\IZD69GN9\Ganti - Semantically Informed Visual Odometry and Mapping.pdf}
}

@book{gaoIntroductionVisualSLAM2022,
  title = {Introduction to {{Visual SLAM}}: From Theory to Practice},
  shorttitle = {Introduction to {{Visual SLAM}}},
  author = {Gao, Xiang and Zhang, Tao},
  date = {2022},
  publisher = {{Springer}},
  location = {{Singapore}},
  url = {https://doi.org/10.1007/978-981-16-4939-4},
  urldate = {2022-01-30},
  abstract = {This book offers a systematic and comprehensive introduction to the visual simultaneous localization and mapping (vSLAM) technology, which is a fundamental and essential component for many applications in robotics, wearable devices, and autonomous driving vehicles. The book starts from very basic mathematic background knowledge such as 3D rigid body geometry, the pinhole camera projection model, and nonlinear optimization techniques, before introducing readers to traditional computer vision topics like feature matching, optical flow, and bundle adjustment. The book employs a light writing style, instead of the rigorous yet dry approach that is common in academic literature. In addition, it includes a wealth of executable source code with increasing difficulty to help readers understand and use the practical techniques. The book can be used as a textbook for senior undergraduate or graduate students, or as reference material for researchers and engineers in related areas.},
  isbn = {9789811649394},
  langid = {english},
  annotation = {OCLC: 1272854923},
  file = {C:\Users\Nav\Zotero\storage\CCP64484\Gao and Zhang - 2022 - Introduction to Visual SLAM from theory to practi.pdf}
}

@unpublished{gontierDELAUNAYDatasetAbstract2022,
  title = {{{DELAUNAY}}: A Dataset of Abstract Art for Psychophysical and Machine Learning Research},
  shorttitle = {{{DELAUNAY}}},
  author = {Gontier, Camille and Jordan, Jakob and Petrovici, Mihai A.},
  date = {2022-01-28},
  eprint = {2201.12123},
  eprinttype = {arxiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/2201.12123},
  urldate = {2022-01-31},
  abstract = {Image datasets are commonly used in psychophysical experiments and in machine learning research. Most publicly available datasets are comprised of images of realistic and natural objects. However, while typical machine learning models lack any domain specific knowledge about natural objects, humans can leverage prior experience for such data, making comparisons between artificial and natural learning challenging. Here, we introduce DELAUNAY, a dataset of abstract paintings and nonfigurative art objects labelled by the artists’ names. This dataset provides a middle ground between natural images and artificial patterns and can thus be used in a variety of contexts, for example to investigate the sample efficiency of humans and artificial neural networks. Finally, we train an off-the-shelf convolutional neural network on DELAUNAY, highlighting several of its intriguing features.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition},
  file = {C:\Users\Nav\Zotero\storage\P3L2GZB2\Gontier et al. - 2022 - DELAUNAY a dataset of abstract art for psychophys.pdf}
}

@unpublished{grisettiLeastSquaresOptimization2020,
  title = {Least {{Squares Optimization}}: From {{Theory}} to {{Practice}}},
  shorttitle = {Least {{Squares Optimization}}},
  author = {Grisetti, Giorgio and Guadagnino, Tiziano and Aloise, Irvin and Colosi, Mirco and Della Corte, Bartolomeo and Schlegel, Dominik},
  date = {2020-02-26},
  eprint = {2002.11051},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2002.11051},
  urldate = {2022-02-02},
  abstract = {Nowadays, Non-Linear Least-Squares embodies the foundation of many Robotics and Computer Vision systems. The research community deeply investigated this topic in the last years, and this resulted in the development of several open-source solvers to approach constantly increasing classes of problems. In this work, we propose a unified methodology to design and develop efficient Least-Squares Optimization algorithms, focusing on the structures and patterns of each specific domain. Furthermore, we present a novel open-source optimization system, that addresses transparently problems with a different structure and designed to be easy to extend. The system is written in modern C++ and can run efficiently on embedded systems3. We validated our approach by conducting comparative experiments on several problems using tandard datasets. The results show that our system achieves state-ofthe-art performances in all tested scenarios.},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {C:\Users\Nav\Zotero\storage\WH4I77YK\Grisetti et al. - 2020 - Least Squares Optimization from Theory to Practic.pdf}
}

@article{grisettiNotesLeastSquaresSLAM2015,
  title = {Notes on {{Least-Squares}} and {{SLAM DRAFT}}},
  author = {Grisetti, Giorgio},
  date = {2015-11},
  file = {C:\Users\Nav\Zotero\storage\DNWKUTXT\Grisetti - Notes on Least-Squares and SLAM DRAFT.pdf}
}

@article{grisettiTutorialGraphBasedSLAM2010,
  title = {A {{Tutorial}} on {{Graph-Based SLAM}}},
  author = {Grisetti, Giorgio and Kümmerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
  date = {2010},
  journaltitle = {IEEE Intelligent Transportation Systems Magazine},
  volume = {2},
  number = {4},
  pages = {31--43},
  issn = {1941-1197},
  doi = {10.1109/MITS.2010.939925},
  abstract = {Being able to build a map of the environment and to simultaneously localize within this map is an essential skill for mobile robots navigating in unknown environments in absence of external referencing systems such as GPS. This so-called simultaneous localization and mapping (SLAM) problem has been one of the most popular research topics in mobile robotics for the last two decades and efficient approaches for solving this task have been proposed. One intuitive way of formulating SLAM is to use a graph whose nodes correspond to the poses of the robot at different points in time and whose edges represent constraints between the poses. The latter are obtained from observations of the environment or from movement actions carried out by the robot. Once such a graph is constructed, the map can be computed by finding the spatial configuration of the nodes that is mostly consistent with the measurements modeled by the edges. In this paper, we provide an introductory description to the graph-based SLAM problem. Furthermore, we discuss a state-of-the-art solution that is based on least-squares error minimization and exploits the structure of the SLAM problems during optimization. The goal of this tutorial is to enable the reader to implement the proposed methods from scratch.},
  eventtitle = {{{IEEE Intelligent Transportation Systems Magazine}}},
  keywords = {Global Positioning System,Graph theory,Mapping,Mobile robots,Tutorials},
  file = {C\:\\Users\\Nav\\Zotero\\storage\\QWW6UIKJ\\Grisetti et al. - 2010 - A Tutorial on Graph-Based SLAM.pdf;C\:\\Users\\Nav\\Zotero\\storage\\3W5XURQV\\5681215.html}
}

@book{hartleyMultipleViewGeometry2004,
  title = {Multiple View Geometry in Computer Vision},
  author = {Hartley, Richard and Zisserman, Andrew},
  date = {2004},
  edition = {2. edition, 17.printing},
  publisher = {{Cambridge Univ. Press}},
  location = {{Cambridge}},
  isbn = {978-0-521-54051-3},
  langid = {english},
  pagetotal = {655}
}

@book{kashaniDeepLearningInterviews2020,
  title = {Deep Learning Interviews: Real World Deep Learning Interview Problems \& Solutions},
  shorttitle = {Deep Learning Interviews},
  author = {Kashani, Shlomo and Ivry, Amir},
  date = {2020},
  abstract = {"Deep Learning Interviews is home to hundreds of fully-solved problems, from a wide range of key topics in AI. It is designed to both rehearse interview or exam specific topics and provide machine learning M.Sc./Ph.D. students, and those awaiting an interview a well-organized overview of the field. The problems it poses are tough enough to cut your teeth on and to dramatically improve your skills-but they're framed within thought-provoking questions and engaging stories. That is what makes the volume so specifically valuable to students and job seekers: it provides them with the ability to speak confidently and quickly on any relevant topic, to answer technical questions clearly and correctly, and to fully understand the purpose and meaning of interview questions and answers. Those are powerful, indispensable advantages to have when walking into the interview room. The book's contents is a large inventory of numerous topics relevant to DL job interviews and graduate level exams. That places this work at the forefront of the growing trend in science to teach a core set of practical mathematical and computational skills. It is widely accepted that the training of every computer scientist must include the fundamental theorems of ML, and AI appears in the curriculum of nearly every university. This volume is designed as an excellent reference for graduates of such programs." -- back cover.},
  isbn = {978-1-916243-56-9},
  langid = {english},
  annotation = {OCLC: 1285868558}
}

@book{kernighanProgrammingLanguage1988,
  title = {The {{C}} Programming Language},
  author = {Kernighan, Brian W. and Ritchie, Dennis M.},
  date = {1988},
  series = {Prentice-{{Hall}} Software Series},
  edition = {2. ed., 52. print},
  publisher = {{Prentice-Hall PTR}},
  location = {{Upper Saddle River, NJ}},
  isbn = {978-0-13-110370-2 978-0-13-110362-7},
  langid = {english},
  pagetotal = {272}
}

@unpublished{levoyImageFormation,
  title = {Image {{Formation}}},
  author = {Levoy, Marc},
  url = {https://youtu.be/y7HrM-fk_Rc?si=k1P46L_LZJ3C6vIk},
  keywords = {Computational Photography,Computer Vision,Photography},
  file = {C:\Users\Nav\Zotero\storage\PWWXBCLF\image-formation-23mar16.key.pdf}
}

@book{mcdowellCrackingCodingInterview2016,
  title = {Cracking the Coding Interview: 189 Programming Questions and Solutions},
  shorttitle = {Cracking the Coding Interview},
  author = {McDowell, Gayle Laakmann},
  date = {2016},
  edition = {6th edition},
  publisher = {{CareerCup, LLC}},
  location = {{Palo Alto, CA}},
  isbn = {978-0-9847828-5-7},
  langid = {english},
  pagetotal = {696},
  file = {C:\Users\Nav\Zotero\storage\SQCBKWR9\McDowell - Cracking the coding interview 189 programming que.pdf}
}

@book{meyersEffective55Specific2005,
  title = {Effective {{C}}++: 55 Specific Ways to Improve Your Programs and Designs.},
  shorttitle = {Effective {{C}}++},
  author = {Meyers, Scott},
  date = {2005},
  isbn = {9780132702065 9781282647497 9786612647499 9780321515827},
  langid = {english},
  annotation = {OCLC: 1156872863}
}

@book{meyersEffectiveModern422015,
  title = {Effective Modern {{C}}++: 42 Specific Ways to Improve Your Use of {{C}}++11 and {{C}}++14},
  shorttitle = {Effective Modern {{C}}++},
  author = {Meyers, Scott},
  date = {2015},
  publisher = {{O'Reilly}},
  location = {{Beijing Köln}},
  isbn = {978-1-4919-0399-5},
  langid = {english},
  pagetotal = {315}
}

@book{meyersEffectiveSTL502014,
  title = {Effective {{STL}}: 50 Specific Ways to Improve Your Use of the {{Standard Template Library}}},
  shorttitle = {Effective {{STL}}},
  author = {Meyers, Scott},
  date = {2014},
  series = {Addison-{{Wesley}} Professional Computing Series},
  edition = {12. print},
  publisher = {{Addison-Wesley}},
  location = {{Boston Munich}},
  isbn = {978-0-201-74962-5},
  langid = {english},
  pagetotal = {260}
}

@online{microsoftDefineDirective,
  title = {\#define Directive ({{C}}/{{C}}++)},
  author = {{Microsoft}},
  url = {https://docs.microsoft.com/en-us/cpp/preprocessor/hash-define-directive-c-cpp},
  urldate = {2022-04-14},
  abstract = {Learn more about: \#define directive (C/C++)},
  langid = {american},
  file = {C:\Users\Nav\Zotero\storage\KZB4H7EA\hash-define-directive-c-cpp.html}
}

@online{microsoftDevelopingContainerUsing,
  title = {Developing inside a {{Container}} Using {{Visual Studio Code Remote Development}}},
  author = {{Microsoft}},
  url = {https://code.visualstudio.com/docs/remote/containers},
  urldate = {2022-02-16},
  abstract = {Developing inside a Container using Visual Studio Code Remote Development},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\LC63BBV4\containers.html}
}

@online{microsoftLambdaExpressions,
  title = {Lambda Expressions in {{C}}++},
  author = {{Microsoft}},
  url = {https://docs.microsoft.com/en-us/cpp/cpp/lambda-expressions-in-cpp},
  urldate = {2022-01-30},
  abstract = {Learn more about: Lambda Expressions in C++},
  langid = {american},
  file = {C:\Users\Nav\Zotero\storage\WYDU7M6C\lambda-expressions-in-cpp.html}
}

@online{microsoftMainFunctionCommandline,
  title = {`main` Function and Command-Line Arguments ({{C}}++)},
  author = {{Microsoft}},
  url = {https://docs.microsoft.com/en-us/cpp/cpp/main-function-command-line-args},
  urldate = {2022-02-01},
  abstract = {The `main` function is the entry point for a C++ program.},
  langid = {american},
  file = {C:\Users\Nav\Zotero\storage\S3TUQW3G\corob-msft - `main` function and command-line arguments (C++).html}
}

@online{microsoftRvalueReferences0x2009,
  title = {Rvalue {{References}}: {{C}}++0x {{Features}} in {{VC10}}, {{Part}} 2},
  shorttitle = {Rvalue {{References}}},
  author = {{Microsoft}},
  date = {2009-02-03T12:27:00+00:00},
  url = {https://devblogs.microsoft.com/cppblog/rvalue-references-c0x-features-in-vc10-part-2/},
  urldate = {2022-06-07},
  abstract = {Part 1 of this series covered lambdas, auto, and static\_assert. ~ Today, I’m going to talk about rvalue references, which enable two different things: move semantics and perfect forwarding.~ This post will be long, because I’m going to explain how rvalue references work in great detail.},
  langid = {american},
  organization = {{Rvalue References: C++0x Features in VC10, Part 2}}
}

@online{microsoftVisualStudioCode,
  title = {Visual {{Studio Code Remote Development}}},
  author = {{Microsoft}},
  url = {https://code.visualstudio.com/docs/remote/remote-overview},
  urldate = {2022-02-16},
  abstract = {Visual Studio Code Remote Development},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\RDW9X44A\remote-overview.html}
}

@unpublished{mullerInstantNeuralGraphics2022,
  title = {Instant {{Neural Graphics Primitives}} with a {{Multiresolution Hash Encoding}}},
  author = {Müller, Thomas and Evans, Alex and Schied, Christoph and Keller, Alexander},
  date = {2022-01-16},
  eprint = {2201.05989},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2201.05989},
  urldate = {2022-02-17},
  abstract = {Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of \$\{1920\textbackslash!\textbackslash times\textbackslash!1080\}\$.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Machine Learning},
  file = {C:\Users\Nav\Zotero\storage\5VPJXPXH\Müller et al. - 2022 - Instant Neural Graphics Primitives with a Multires.pdf}
}

@book{murphyMachineLearningProbabilistic2013,
  title = {Machine Learning: A Probabilistic Perspective},
  shorttitle = {Machine Learning},
  author = {Murphy, Kevin P.},
  date = {2013},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {4. print. (fixed many typos)},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass.}},
  isbn = {978-0-262-01802-9},
  langid = {english},
  pagetotal = {1071}
}

@book{nocedalNumericalOptimization2006,
  title = {Numerical Optimization},
  author = {Nocedal, Jorge and Wright, Stephen J.},
  date = {2006},
  series = {Springer Series in Operations Research},
  edition = {2nd ed},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-30303-1},
  pagetotal = {664},
  keywords = {Mathematical optimization},
  annotation = {OCLC: ocm68629100}
}

@online{oquabDINOv2LearningRobust2023,
  title = {{{DINOv2}}: {{Learning Robust Visual Features}} without {{Supervision}}},
  shorttitle = {{{DINOv2}}},
  author = {Oquab, Maxime and Darcet, Timothée and Moutakanni, Théo and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and Assran, Mahmoud and Ballas, Nicolas and Galuba, Wojciech and Howes, Russell and Huang, Po-Yao and Li, Shang-Wen and Misra, Ishan and Rabbat, Michael and Sharma, Vasu and Synnaeve, Gabriel and Xu, Hu and Jegou, Hervé and Mairal, Julien and Labatut, Patrick and Joulin, Armand and Bojanowski, Piotr},
  date = {2023-04-14},
  eprint = {2304.07193},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.07193},
  url = {http://arxiv.org/abs/2304.07193},
  urldate = {2023-10-05},
  abstract = {The recent breakthroughs in natural language processing for model pretraining on large quantities of data have opened the way for similar foundation models in computer vision. These models could greatly simplify the use of images in any system by producing all-purpose visual features, i.e., features that work across image distributions and tasks without finetuning. This work shows that existing pretraining methods, especially self-supervised methods, can produce such features if trained on enough curated data from diverse sources. We revisit existing approaches and combine different techniques to scale our pretraining in terms of data and model size. Most of the technical contributions aim at accelerating and stabilizing the training at scale. In terms of data, we propose an automatic pipeline to build a dedicated, diverse, and curated image dataset instead of uncurated data, as typically done in the self-supervised literature. In terms of models, we train a ViT model (Dosovitskiy et al., 2020) with 1B parameters and distill it into a series of smaller models that surpass the best available all-purpose features, OpenCLIP (Ilharco et al., 2021) on most of the benchmarks at image and pixel levels.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {C:\Users\Nav\Zotero\storage\AVR5637B\Oquab et al. - 2023 - DINOv2 Learning Robust Visual Features without Supervision.pdf}
}

@article{qinVINSMonoRobustVersatile2018,
  title = {{{VINS-Mono}}: {{A Robust}} and {{Versatile Monocular Visual-Inertial State Estimator}}},
  shorttitle = {{{VINS-Mono}}},
  author = {Qin, Tong and Li, Peiliang and Shen, Shaojie},
  date = {2018-08},
  journaltitle = {IEEE Transactions on Robotics},
  shortjournal = {IEEE Trans. Robot.},
  volume = {34},
  number = {4},
  eprint = {1708.03852},
  eprinttype = {arxiv},
  pages = {1004--1020},
  issn = {1552-3098, 1941-0468},
  doi = {10.1109/TRO.2018.2853729},
  url = {http://arxiv.org/abs/1708.03852},
  urldate = {2022-02-07},
  abstract = {A monocular visual-inertial system (VINS), consisting of a camera and a low-cost inertial measurement unit (IMU), forms the minimum sensor suite for metric six degreesof-freedom (DOF) state estimation. However, the lack of direct distance measurement poses significant challenges in terms of IMU processing, estimator initialization, extrinsic calibration, and nonlinear optimization. In this work, we present VINSMono: a robust and versatile monocular visual-inertial state estimator. Our approach starts with a robust procedure for estimator initialization and failure recovery. A tightly-coupled, nonlinear optimization-based method is used to obtain high accuracy visual-inertial odometry by fusing pre-integrated IMU measurements and feature observations. A loop detection module, in combination with our tightly-coupled formulation, enables relocalization with minimum computation overhead. We additionally perform four degrees-of-freedom pose graph optimization to enforce global consistency. We validate the performance of our system on public datasets and real-world experiments and compare against other state-of-the-art algorithms. We also perform onboard closed-loop autonomous flight on the MAV platform and port the algorithm to an iOS-based demonstration. We highlight that the proposed work is a reliable, complete, and versatile system that is applicable for different applications that require high accuracy localization. We open source our implementations for both PCs1 and iOS mobile devices2.},
  langid = {english},
  keywords = {Computer Science - Robotics},
  file = {C:\Users\Nav\Zotero\storage\NS9EJQEP\Qin et al. - 2018 - VINS-Mono A Robust and Versatile Monocular Visual.pdf}
}

@online{scroggsAvoidUrgencyTrap2020,
  title = {Avoid the "{{Urgency Trap}}" with the {{Eisenhower Matrix}}},
  author = {Scroggs, Laura},
  date = {2020},
  url = {https://todoist.com/productivity-methods/eisenhower-matrix},
  urldate = {2022-02-01},
  abstract = {President Eisenhower used this simple grid to distinguish between the Urgent and the Important and prioritize his time and tasks accordingly. Learn how to apply his framework to your own tasks and projects.},
  langid = {english},
  organization = {{Todoist}},
  file = {C:\Users\Nav\Zotero\storage\Y34D6WTZ\eisenhower-matrix.html}
}

@article{sibleySlidingWindowFilter2006,
  title = {A {{Sliding Window Filter}} for {{SLAM}}},
  author = {Sibley, Gabe},
  date = {2006},
  pages = {17},
  abstract = {This note describes a Sliding Window Filter that is an on-line constanttime approximation to the feature-based 6-degree-of-freedom full Batch Least Squares Simultaneous Localization and Mapping (SLAM) problem. We contend that for SLAM to be useful in large environments and over extensive run-times, its computational time complexity must be constant, and its memory requirements should be at most linear. Under this constraint, the “best” algorithm will be the one that comes closest to matching the all-time maximum-likelihood estimate of the full SLAM problem, while also maintaining consistency. We start by formulating SLAM as a Batch Least Squares state estimation problem, and then show how to modify the Batch estimator into an approximate Sliding Window Batch/Recursive framework that achieves constant time complexity and linear space complexity. We argue that viewing SLAM from the Sliding Window Least Squares perspective is very useful for understanding the structure of the problem. This perspective is general, capable of subsuming a number of common estimation techniques such as Bundle Adjustment and Extended Kalman Filter SLAM. By tuning the sliding window, the algorithm can scale from exhaustive Batch solutions to fast incremental solutions; if the window encompasses all time, the solution is algebraically equivalent to full SLAM; if only one time step is maintained, the solution is algebraically equivalent to the Extended Kalman Filter SLAM solution. The Sliding Window Filter enables other interesting properties, like continuous sub-mapping, lazy data association, undelayed or delayed landmark initialization, and incremental robust estimation. We test the algorithm in simulations using stereo vision exterioceptive sensors and inertial measurement proprioceptive sensors. Initial experiments show that the SWF approaches the performance of the optimal batch estimator, even for small windows on the order of 5-10 frames.},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\3X8W6AWZ\Sibley - A Sliding Window Filter for SLAM.pdf}
}

@incollection{sibleySlidingWindowFilter2008,
  title = {A {{Sliding Window Filter}} for {{Incremental SLAM}}},
  booktitle = {Unifying {{Perspectives}} in {{Computational}} and {{Robot Vision}}},
  author = {Sibley, Gabe and Matthies, Larry and Sukhatme, Gaurav},
  editor = {Kragic, Danica and Kyrki, Ville},
  date = {2008},
  volume = {8},
  pages = {103--112},
  publisher = {{Springer US}},
  location = {{Boston, MA}},
  doi = {10.1007/978-0-387-75523-6_7},
  url = {http://link.springer.com/10.1007/978-0-387-75523-6_7},
  urldate = {2022-02-02},
  isbn = {978-0-387-75521-2 978-0-387-75523-6},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\8FJKQV2D\Sibley et al. - 2008 - A Sliding Window Filter for Incremental SLAM.pdf}
}

@book{skienaAlgorithmDesignManual2008,
  title = {The Algorithm Design Manual},
  author = {Skiena, Steven S.},
  date = {2008},
  edition = {2nd ed},
  publisher = {{Springer}},
  location = {{London}},
  isbn = {978-1-84800-069-8 978-1-84800-070-4},
  pagetotal = {730},
  keywords = {Computer algorithms},
  annotation = {OCLC: ocn228582051}
}

@article{solaMicroLieTheory2018,
  title = {A Micro {{Lie}} Theory for State Estimation in Robotics},
  author = {Solà, Joan and Deray, Jeremie and Atchuthan, Dinesh},
  date = {2018-12-04},
  url = {https://arxiv.org/abs/1812.01537v9},
  urldate = {2022-02-03},
  abstract = {A Lie group is an old mathematical abstract object dating back to the XIX century, when mathematician Sophus Lie laid the foundations of the theory of continuous transformation groups. As it often happens, its usage has spread over diverse areas of science and technology many years later. In robotics, we are recently experiencing an important trend in its usage, at least in the fields of estimation, and particularly in motion estimation for navigation. Yet for a vast majority of roboticians, Lie groups are highly abstract constructions and therefore difficult to understand and to use. This may be due to the fact that most of the literature on Lie theory is written by and for mathematicians and physicists, who might be more used than us to the deep abstractions this theory deals with. In estimation for robotics it is often not necessary to exploit the full capacity of the theory, and therefore an effort of selection of materials is required. In this paper, we will walk through the most basic principles of the Lie theory, with the aim of conveying clear and useful ideas, and leave a significant corpus of the Lie theory behind. Even with this mutilation, the material included here has proven to be extremely useful in modern estimation algorithms for robotics, especially in the fields of SLAM, visual odometry, and the like. Alongside this micro Lie theory, we provide a chapter with a few application examples, and a vast reference of formulas for the major Lie groups used in robotics, including most jacobian matrices and the way to easily manipulate them. We also present a new C++ template-only library implementing all the functionality described here.},
  langid = {english},
  file = {C\:\\Users\\Nav\\Zotero\\storage\\97CX88AE\\Solà et al. - 2018 - A micro Lie theory for state estimation in robotic.pdf;C\:\\Users\\Nav\\Zotero\\storage\\4JKKQ5I8\\1812.html}
}

@unpublished{strangFactorizationLU2017,
  title = {Factorization into {{A}} = {{LU}}},
  author = {Strang, Gilbert},
  date = {2017-04-24},
  url = {https://www.youtube.com/watch?v=MsIvs_6vC38},
  urldate = {2022-02-02},
  abstract = {MIT 18.06 Linear Algebra, Spring 2005 Instructor: Gilbert Strang View the complete course: http://ocw.mit.edu/18-06S05 YouTube Playlist: https://www.youtube.com/playlist?list... 4. Factorization into A = LU},
  file = {C:\Users\Nav\Zotero\storage\ERT8FHQT\MIT OpenCourseWare - 2017 - 4. Factorization into A = LU.pdf}
}

@book{strangIntroductionLinearAlgebra2016,
  title = {Introduction to Linear Algebra},
  author = {Strang, Gilbert},
  date = {2016},
  edition = {5th edition},
  publisher = {{Cambridge press}},
  location = {{Wellesley}},
  isbn = {978-0-9802327-7-6},
  langid = {english}
}

@book{stroustrupTour2014,
  title = {A Tour of {{C}}++},
  author = {Stroustrup, Bjarne},
  date = {2014},
  series = {The {{C}}++ In-Depth Series},
  publisher = {{Addison-Wesley}},
  location = {{Upper Saddle River, NJ}},
  isbn = {978-0-321-95831-0},
  pagetotal = {181},
  keywords = {C++ (Computer program language)}
}

@article{zhangFlexibleNewTechnique2000,
  title = {A Flexible New Technique for Camera Calibration},
  author = {Zhang, Zhengyou},
  date = {2000-11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Machine Intell.},
  volume = {22},
  number = {11},
  pages = {1330--1334},
  issn = {01628828},
  doi = {10.1109/34.888718},
  url = {http://ieeexplore.ieee.org/document/888718/},
  urldate = {2022-02-07},
  abstract = {We propose a flexible new technique to easily calibrate a camera. It is well suited for use without specialized knowledge of 3D geometry or computer vision. The technique only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique, and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one step from laboratory environments to real world use.},
  langid = {english},
  file = {C:\Users\Nav\Zotero\storage\C9Q893DR\Zhang - 2000 - A flexible new technique for camera calibration.pdf}
}
